{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as pdr\n",
    "from pandas_datareader import data\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting Tickers and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market Capitalization Top-Ranked Companies in U.S.\n",
    "tickers = ['AAPL', 'ADBE', 'AMZN', 'BAC', 'CMCSA', 'CSCO', 'CVX', 'DIS',\n",
    "           'GOOG', 'HD', 'INTC', 'JNJ', 'JPM', 'KO', 'MA', 'MSFT', 'NFLX', 'NKE',\n",
    "           'NVDA', 'ORCL', 'PFE', 'PG', 'T', 'TM', 'TSLA', 'UNH', 'V', 'VZ', 'WMT',\n",
    "           'XOM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Device - If you have gpu, you can change the device 'gpu'\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Class of LSTM Model\n",
    "class LSTM_model(nn.Module):\n",
    "  def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "    super(LSTM_model, self).__init__()\n",
    "    self.num_classes = num_classes #number of classes\n",
    "    self.num_layers = num_layers #number of layers\n",
    "    self.input_size = input_size #input size\n",
    "    self.hidden_size = hidden_size #hidden state\n",
    "    self.seq_length = seq_length #sequence length\n",
    " \n",
    "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True) #LSTM layer\n",
    "    self.fc = nn.Linear(hidden_size, num_classes) #fully connected last layer\n",
    "\n",
    "  def forward(self,x):\n",
    "    h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #hidden state\n",
    "    c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) #internal state   \n",
    "    # Propagate input through LSTM\n",
    "\n",
    "    out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        \n",
    "    # Decode the hidden state of the last time step\n",
    "    out = self.fc(out[:, -1, :])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAE(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred)))\n",
    "\n",
    "def MSE(y_true, y_pred):\n",
    "    return np.mean(np.square((y_true - y_pred)))\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square((y_true - y_pred))))\n",
    "\n",
    "def MAPE(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def MPE(y_true, y_pred): \n",
    "    return np.mean((y_true - y_pred) / y_true) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setting Hyperparameters and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "learning_rate = 0.001\n",
    "\n",
    "input_size = 6 # number of features\n",
    "hidden_size = 2 # number of features in hidden state\n",
    "num_layers = 1 # number of stacked LSTM layers\n",
    "\n",
    "num_classes = 1 #number of output classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_lstm = pd.DataFrame()\n",
    "df_metrics_lstm = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tickers)):\n",
    "    df = pd.read_csv('./stock_price_data/' + tickers[i]+'.csv', index_col = 0)\n",
    "    \n",
    "    df_s = pd.DataFrame()\n",
    "    \n",
    "    df_s['High'] = (df['High'] - df['High'].min())/(df['High'].max() - df['High'].min())\n",
    "    df_s['Low'] = (df['Low'] - df['Low'].min())/(df['Low'].max() - df['Low'].min())\n",
    "    df_s['Open'] = (df['Open'] - df['Open'].min())/(df['Open'].max() - df['Open'].min())\n",
    "    df_s['Close'] = (df['Close'] - df['Close'].min())/(df['Close'].max() - df['Close'].min())\n",
    "    df_s['Volume'] = (df['Volume'] - df['Volume'].min())/(df['Volume'].max() - df['Volume'].min())\n",
    "    df_s['Adj Close'] = (df['Adj Close'] - df['Adj Close'].min())/(df['Adj Close'].max() - df['Adj Close'].min())\n",
    "    \n",
    "    X = np.array(df_s) # Using high price, low price, Open price, Close price, Volume, and Adjusted Close Price to predict adjusted close price\n",
    "    y = np.array(df_s.iloc[:, 5:6]) #Predicting adjusted close price\n",
    "\n",
    "    train_pct = 0.8\n",
    "    split = int(train_pct * len(X))\n",
    "    X_train, X_test, y_train, y_test = X[:split, :], X[split+1:-1 :], y[1:split+1, :], y[split+2:, :] \n",
    "\n",
    "    X_train_tensors = Variable(torch.Tensor(X_train))\n",
    "    X_test_tensors = Variable(torch.Tensor(X_test))\n",
    "\n",
    "    y_train_tensors = Variable(torch.Tensor(y_train))\n",
    "    y_test_tensors = Variable(torch.Tensor(y_test))\n",
    "\n",
    "    X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
    "    X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) \n",
    "\n",
    "    LSTM_1 = LSTM_model(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1]).to(device)\n",
    "\n",
    "    loss_function = torch.nn.MSELoss()    # mean-squared error for regression\n",
    "    optimizer = torch.optim.Adam(LSTM_1.parameters(), lr=learning_rate)  # adam optimizer\n",
    "\n",
    "    print(tickers[i])\n",
    "    for epoch in range(num_epochs+1):\n",
    "        outputs = LSTM_1.forward(X_train_tensors_final.to(device)) #forward pass\n",
    "        optimizer.zero_grad() #caluclate the gradient, manually setting to 0\n",
    "\n",
    "        # obtain the loss function\n",
    "        loss = loss_function(outputs, y_train_tensors.to(device))\n",
    "\n",
    "        loss.backward() #calculates the loss of the loss function\n",
    "\n",
    "        optimizer.step() #improve from loss, i.e backprop\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch: %d, Loss: %1.4f\" % (epoch, loss.item()))\n",
    "\n",
    "    X_data = X_test\n",
    "    y_data = y_test\n",
    "\n",
    "    df_X = Variable(torch.Tensor(X_data))\n",
    "    df_y = Variable(torch.Tensor(y_data))\n",
    "\n",
    "    df_X = torch.reshape(df_X, (df_X.shape[0], 1, df_X.shape[1]))\n",
    "    train_predict = LSTM_1(df_X.to(device))#forward pass\n",
    "    y_predict = train_predict.data.detach().cpu().numpy() #numpy conversion\n",
    "    \n",
    "    y_predict = y_predict * (df['Adj Close'].max() - df['Adj Close'].min()) + df['Adj Close'].min() #reverse transformation\n",
    "    y_true = np.array(df.iloc[split+2:, 5:6])\n",
    "    \n",
    "    metrics_value_lstm = pd.DataFrame([MAE(y_true, y_predict), MSE(y_true, y_predict), RMSE(y_true, y_predict), MAPE(y_true, y_predict), MPE(y_true, y_predict)])\n",
    "    metrics_value_lstm.columns = [tickers[i]]\n",
    "    metrics_value_lstm.index = ['MAE', 'MSE', 'RMSE', 'MAPE', 'MPE']\n",
    "    df_metrics_lstm = pd.concat([df_metrics_lstm, metrics_value_lstm], axis = 1)\n",
    "    df_results_lstm_temp = pd.DataFrame(y_predict)\n",
    "    df_results_lstm_temp.columns = [tickers[i]]\n",
    "    df_results_lstm = pd.concat([df_results_lstm, df_results_lstm_temp], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Saving Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_lstm.to_csv('Results of Error Metrics (LSTM).csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Building Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_lstm.index = df.iloc[len(df) - len(df_results_lstm):, ].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.DataFrame()\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    df = pd.read_csv('./stock_price_data/' + tickers[i]+'.csv', index_col = 0)\n",
    "    close = df['Adj Close']\n",
    "    df_close = pd.DataFrame(close)\n",
    "    df_close.columns = [tickers[i]]\n",
    "    df_original = pd.concat([df_original, df_close], axis=1)\n",
    "\n",
    "ret_daily = df_results_lstm.pct_change()\n",
    "ret_daily = ret_daily.iloc[1:, ]\n",
    "\n",
    "ret_daily_original = df_original.iloc[len(df) - len(df_results_lstm) - 251:, ]\n",
    "ret_daily_original = ret_daily_original.pct_change()\n",
    "ret_daily_original = ret_daily_original.iloc[1:, ]\n",
    "\n",
    "n_assets = len(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.DataFrame()\n",
    "\n",
    "for i in range(len(tickers)):\n",
    "    df = pd.read_csv('./stock_price_data/' + tickers[i]+'.csv', index_col = 0)\n",
    "    close = df['Adj Close']\n",
    "    df_close = pd.DataFrame(close)\n",
    "    df_close.columns = [tickers[i]]\n",
    "    df_original = pd.concat([df_original, df_close], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Portfolio Optimization with Stock Price Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_sharpe(weights, returns, covmat, rf):\n",
    "    ret = np.dot(weights, returns)\n",
    "    vol = np.sqrt(np.dot(weights.T, np.dot(covmat, weights)))\n",
    "    return 1/((ret-rf)/np.sqrt(vol)) # 1/Sharpe Ratio -> Maximize Sharpe Ratio Using Minimize Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_lstm = []\n",
    "for i in range(0, len(ret_daily)-1):\n",
    "    ret_annual = pd.concat([ret_daily_original[i:i+251], ret_daily[i:i+1]]).mean() * 252\n",
    "    cov_annual = pd.concat([ret_daily_original[i:i+251], ret_daily[i:i+1]]).cov() * 252\n",
    "    rf = 0.01\n",
    "    w0 = np.ones([n_assets])/n_assets\n",
    "    bnds = tuple((0., 1.) for i in range(n_assets))\n",
    "    cons = ({'type': 'eq', 'fun': lambda w:  np.sum(w) - 1}) \n",
    "    res = minimize(obj_sharpe, w0, (ret_annual, cov_annual, rf), method='SLSQP', bounds=bnds, constraints=cons)\n",
    "    profit = (ret_daily_original.iloc[i+252] * res.x).sum()\n",
    "    portfolio_lstm.append(profit)\n",
    "    print(profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_lstm = pd.DataFrame(portfolio_lstm) - 0.0003 # Upper bound of security transaction tax\n",
    "portfolio_lstm.index = ret_daily.index[1:]\n",
    "portfolio_lstm.columns = ['Portfolio Return']\n",
    "\n",
    "data_lstm = pd.DataFrame([['2018-10-24',0]], columns=['Date','Portfolio Return'])\n",
    "data_lstm.index = data_lstm['Date']\n",
    "data_lstm = data_lstm.drop(['Date'], axis=1)\n",
    "\n",
    "portfolio_lstm = pd.concat([data_lstm, portfolio_lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_return_lstm = []\n",
    "\n",
    "for i in range(0, len(portfolio_lstm)):\n",
    "    if i == 0:\n",
    "        c_return_lstm_v_init = 0\n",
    "        c_return_lstm.append(c_return_lstm_v_init)\n",
    "    else:\n",
    "        c_return_lstm_v = (c_return_lstm[i-1] + 1) * (portfolio_lstm['Portfolio Return'][i] + 1) - 1\n",
    "        c_return_lstm.append(c_return_lstm_v)\n",
    "        \n",
    "c_return_lstm = pd.DataFrame(c_return_lstm)\n",
    "c_return_lstm.index = portfolio_lstm.index\n",
    "\n",
    "portfolio_lstm_final = pd.concat([portfolio_lstm, c_return_lstm], axis = 1)\n",
    "portfolio_lstm_final.columns = ['Portfolio Return', 'Cumulative Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 0.015\n",
    "std_portfolio_lstm = portfolio_lstm_final['Portfolio Return'][1:].std()\n",
    "Sharpe_lstm = (portfolio_lstm_final['Portfolio Return'][1:] - risk_free_rate)/std_portfolio_lstm\n",
    "Sharpe_lstm = Sharpe_lstm.mean()\n",
    "print('Sharpe ratio (Portfolio with LSTM Price Prediction Results): %.2f' % Sharpe_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_lstm_final.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. Equally-Weighted Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_eqw = []\n",
    "\n",
    "for i in range(0, len(ret_daily)-1):\n",
    "    weights = np.ones([n_assets])/n_assets\n",
    "    profit_eqw = (ret_daily_original.iloc[i+252] * weights).sum()\n",
    "    portfolio_eqw.append(profit_eqw)\n",
    "\n",
    "portfolio_eqw = pd.DataFrame(portfolio_eqw) \n",
    "portfolio_eqw.index = ret_daily.index[1:]\n",
    "portfolio_eqw.columns = ['Portfolio Return']\n",
    "    \n",
    "data_eqw = pd.DataFrame([['2018-10-24',0]], columns=['Date','Portfolio Return'])\n",
    "data_eqw.index = data_eqw['Date']\n",
    "data_eqw = data_eqw.drop(['Date'], axis=1)\n",
    "\n",
    "portfolio_eqw = pd.concat([data_eqw, portfolio_eqw])\n",
    "\n",
    "c_return_eqw = []\n",
    "\n",
    "for i in range(0, len(portfolio_eqw)):\n",
    "    if i == 0:\n",
    "        c_return_eqw_v_init = 0\n",
    "        c_return_eqw.append(c_return_eqw_v_init)\n",
    "    else:\n",
    "        c_return_eqw_v = (c_return_eqw[i-1] + 1) * (portfolio_eqw['Portfolio Return'][i] + 1) - 1\n",
    "        c_return_eqw.append(c_return_eqw_v)\n",
    "        \n",
    "c_return_eqw = pd.DataFrame(c_return_eqw)\n",
    "c_return_eqw.index = portfolio_eqw.index\n",
    "\n",
    "portfolio_eqw_final = pd.concat([portfolio_eqw, c_return_eqw], axis = 1)\n",
    "portfolio_eqw_final.columns = ['Portfolio Return', 'Cumulative Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 0.015\n",
    "std_portfolio_eqw = portfolio_eqw_final['Portfolio Return'][1:].std()\n",
    "Sharpe_eqw = (portfolio_eqw_final['Portfolio Return'][1:] - risk_free_rate)/std_portfolio_eqw\n",
    "Sharpe_eqw = Sharpe_eqw.mean()\n",
    "print('Sharpe ratio (Equally-Weighted Portfolio): %.2f' % Sharpe_eqw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_eqw_final.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-3. Capitalization Weighted Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap_data = data.get_quote_yahoo(tickers)['marketCap']\n",
    "market_cap = pd.DataFrame(market_cap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap = market_cap / market_cap.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_cap = np.array(market_cap['marketCap'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_mcw = []\n",
    "\n",
    "for i in range(0, len(ret_daily)-1):\n",
    "    weights = market_cap\n",
    "    profit_mcw = (ret_daily_original.iloc[i+252] * weights).sum()\n",
    "    portfolio_mcw.append(profit_mcw)\n",
    "\n",
    "portfolio_mcw = pd.DataFrame(portfolio_mcw) \n",
    "portfolio_mcw.index = ret_daily.index[1:]\n",
    "portfolio_mcw.columns = ['Portfolio Return']\n",
    "\n",
    "data_mcw = pd.DataFrame([['2018-10-24',0]], columns=['Date','Portfolio Return'])\n",
    "data_mcw.index = data_mcw['Date']\n",
    "data_mcw = data_mcw.drop(['Date'], axis=1)\n",
    "\n",
    "portfolio_mcw = pd.concat([data_mcw, portfolio_mcw])\n",
    "\n",
    "c_return_mcw = []\n",
    "\n",
    "for i in range(0, len(portfolio_mcw)):\n",
    "    if i == 0:\n",
    "        c_return_mcw_v_init = 0\n",
    "        c_return_mcw.append(c_return_mcw_v_init)\n",
    "    else:\n",
    "        c_return_mcw_v = (c_return_mcw[i-1] + 1) * (portfolio_mcw['Portfolio Return'][i] + 1) - 1\n",
    "        c_return_mcw.append(c_return_mcw_v)\n",
    "        \n",
    "c_return_mcw = pd.DataFrame(c_return_mcw)\n",
    "c_return_mcw.index = portfolio_mcw.index\n",
    "\n",
    "portfolio_mcw_final = pd.concat([portfolio_mcw, c_return_mcw], axis = 1)\n",
    "portfolio_mcw_final.columns = ['Portfolio Return', 'Cumulative Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 0.015\n",
    "std_portfolio_mcw = portfolio_mcw_final['Portfolio Return'][1:].std()\n",
    "Sharpe_mcw = (portfolio_mcw_final['Portfolio Return'][1:] - risk_free_rate)/std_portfolio_mcw\n",
    "Sharpe_mcw = Sharpe_mcw.mean()\n",
    "print('Sharpe ratio (Market Capitalization-Weighted Portfolio): %.2f' % Sharpe_mcw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_mcw_final.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plotting Cumulative Returns of Portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (32,18)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True \n",
    "plt.rcParams.update({'font.size': 50})\n",
    "plt.rcParams['lines.linewidth'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_lstm_final.index = pd.to_datetime(portfolio_lstm_final.index)\n",
    "portfolio_eqw_final.index = pd.to_datetime(portfolio_eqw_final.index)\n",
    "portfolio_mcw_final.index = pd.to_datetime(portfolio_mcw_final.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line1 = plt.plot(portfolio_lstm_final.index.to_pydatetime(), portfolio_lstm_final['Cumulative Return'], label = 'Portfolio Using LSTM Prediction Results', color = 'red')\n",
    "line2 = plt.plot(portfolio_eqw_final.index.to_pydatetime(), portfolio_eqw_final['Cumulative Return'], label = 'Equally Weighted Portfolio', color = 'deepskyblue')\n",
    "line3 = plt.plot(portfolio_mcw_final.index.to_pydatetime(), portfolio_mcw_final['Cumulative Return'], label = 'Capitalization Weighted Portfolio', color = 'blue')\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.ylim(-0.6, 5.1)\n",
    "plt.legend(prop={'size':15})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
